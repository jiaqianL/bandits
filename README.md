# Multi-Armed Bandit Algorithms

Implementation and simulation tests of various Multi-Armed Bandit Algorithms in Python.


Most of this repository is based and adapted from https://github.com/johnmyleswhite/BanditsBook
The Gradient Descent algorithms are based on https://gist.github.com/awjuliani/902fe41c3a9efe27299e72aee1b3158c#file-simplepolicy-ipynb
